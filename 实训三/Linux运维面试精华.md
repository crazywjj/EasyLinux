[TOC]





# Linux运维面试精华

# 基础必会

## 什么是运维？运维包含哪些？

1）运维是指大型组织已经建立好的网络软硬件的维护，就是要保证业务的上线与运作的正常，在他运转的过程中，对他进行维护，他集合了网络、系统、数据库、开发、安全、监控于一身的技术，运维又包括很多种，有DBA运维、网站运维、虚拟化运维、监控运维、游戏运维等等

具体分工职责：

开发运维：是给应用运维开发运维工具和运维平台的
应用运维：是给业务上线、维护和做故障排除的，用开发运维开发出来的工具给业务上线、维护、做故障排查
系统运维：是给应用运维提供业务上的基础设施，比如：系统、网络、监控、硬件等等

总结：开发运维和系统运维给应用运维提供了“工具”和“基础设施”上的支撑开发运维、应用运维和系统运维他们的工作是环环相扣的



## 在工作中，运维人员经常需要跟运营人员打交道，请问运营人员是做什么工作的？

游戏运营要做的一个事情除了协调工作以外，还需要与各平台沟通，做好开服的时间、开服数、用户导量、活动等计划



## 如果给你三百台服务器，如何对其进行管理？

管理3百台服务器的方式：

1）设定跳板机，使用统一账号登录，便于安全与登录的考量。

2）使用salt、ansiable、puppet进行系统的统一调度与配置的统一管理。

3）建立简单的服务器的系统、配置、应用的cmdb信息管理。便于查阅每台服务器上的各种信息记录。



## 你对运维工程师的理解和以及工作的认识

运维工程师在公司当中责任重大，需要保证时刻为公司及客户提供最高、最快、最稳定、最安全的服务。

运维工程师的一个小小的失误，很有可能会对公司及客户造成重大损失；因此运维工程师的工作需要严谨及富有创新精神。



## 服务器开不了机怎么办

A、造成服务器故障的原因可能有以下几点：

1.服务器电源有问题

2.服务器系统文件丢失，硬件问题，散热不良造成蓝屏和死机

3.服务器网络参数配置有误，物理链路原因等 

B、如何排查服务器故障的处理步骤如下：

![1585298560818](assets/1585298560818.png) 





## 请列出你了解的web服务器负载架构

```
Nginx
Haproxy
Keepalived
LVS
```







## Linux 磁盘空间满（含inode满）问题排查方法

**问题描述**

在云服务器ECS Linux系统内创建文件时，出现类似如下空间不足提示：

```
No space left on device …
```

**问题原因**

- 磁盘分区空间使用率达到百分之百。

- 磁盘分区inode使用率达到百分之百。

- 僵尸文件：已删除文件因句柄被占用未释放导致相应空间未释放。

挂载点覆盖：在原有文件系统的相应目录下已经存在大量文件。挂载了新磁盘后，导致使用 df 命令能统计到相关空间使用，而使用 su 命令统计不到。

**处理办法**

不同的原因需要通过不同的方法解决：

```bash
分区容量满
inode容量满
修改inode数量
僵尸文件分析删除
挂载点覆盖
分区容量满
```

1、分区容量满导致磁盘空间满

远程连接Linux实例。
运行 df -h 查看磁盘使用率。
返回结果里 Mounted on 下显示的是挂载目录。

循环执行如下指令，找到容量比较大的目录并进入目录，直到找到最精确的文件或目录，再结合业务情况等判断，删除相关文件或目录。您也可以购买更大的数据盘来分担处理。

```
cd /
du -sh *
```



2、inode容量满

如果是inode容量满导致磁盘空间满，按以下步骤操作：

远程连接Linux实例。
运行以下命令分析根目录下每个目录下面有多少个文件。

```
for i in /*; do echo $i; find $i | wc -l; done
```

逐层进入inode占用最高的目录，继续执行上述指令，逐步定位占用过高空间的文件或目录，最后进行相应清理。



**修改inode数量**

ECS Linux 实例的inode节点中，记录了文件的类型、大小、权限、所有者、文件连接的数目、创建时间与更新时间等重要的信息，还有一个比较重要的内容就是指向数据块的指针。一般情况不需要特殊配置；如果存放文件很多，需要配置。有时磁盘空间有剩余但是不能存放文件，可能是由于inode耗尽所致。

按以下步骤调整inode节点数量：

注意：
inode的调整需要重新格式化磁盘，请确保您已经备份了数据再执行以下操作。

远程连接Linux实例。
运行以下命令查询inode使用情况。
df  -i



僵尸文件分析删除
如果磁盘和inode都没有问题，则需要查看是否存在未被清除句柄的僵死文件。这些文件实际上已经被删除，但是有服务程序在使用这些文件，导致这些文件一直被占用，无法释放磁盘空间。如果这些文件过多，会占用很大的磁盘空间。

按以下步骤查看并删除僵尸文件：

```
yum install lsof -y
lsof |grep delete | more
```

采用以下方法释放句柄，以清除僵尸文件：

- 重启服务器。

- 正常停止或杀掉占用这些文件的服务进程。

  

**挂载点覆盖**

先取消磁盘挂载，再检查原挂载目录下的空间占用情况。

























 

## 什么叫CDN？

1.即内容分发网络

2.其目的是通过在现有的Internet中增加一层新的网络架构，将网站的内容发布到最接近用户的网络边缘，使用户可就近取得所需的内容，提高用户访问网站的速度

 

## 什么叫网站灰度发布？

灰度发布是指在黑与白之间，能够平滑过渡的一种发布方式

AB test就是一种灰度发布方式，让一部用户继续用A，一部分用户开始用B，如果用户对B没有什么反对意见，那么逐步扩大范围，把所有用户都迁移到B上面来灰度发布可以保证整体系统的稳定，在初始灰度的时候就可以发现、调整问题，以保证其影响度



## RabbitMQ是什么？

RabbitMQ也就是消息队列中间件，消息中间件是在消息的传息过程中保存消息的容器
消息中间件再将消息从它的源中到它的目标中标时充当中间人的作用
队列的主要目的是提供路由并保证消息的传递；如果发送消息时接收者不可用
消息队列不会保留消息，直到可以成功地传递为止，当然，消息队列保存消息也是有期限地







 





## 如何优化 Linux系统（可以不说太具体）？

```
不用root，添加普通用户，通过sudo授权管理
更改默认的远程连接SSH服务端口及禁止root用户远程连接
定时自动更新服务器时间
配置国内yum源
关闭selinux及iptables（iptables工作场景如果有外网IP一定要打开，高并发除外）
调整文件描述符的数量
精简开机启动服务（crond rsyslog network sshd）
内核参数优化（/etc/sysctl.conf）
更改字符集，支持中文，但建议还是用英文字符集，防止乱码
锁定关键系统文件
清空/etc/issue，去除系统及内核版本登录前的屏幕显示
```



## 取出 linux 中 eth0 的 IP 地址

```shell
cut方法1：ifconfig eth0|sed -n ‘2p’|cut -d “:” -f2|cut -d ” ” -f1192.168.20.130
awk方法2：ifconfig eth0|awk ‘NR==2’|awk -F “:” ‘{print $2}’|awk ‘{print $1}’192.168.20.130
awk多分隔符方法3：ifconfig eth0|awk ‘NR==2’|awk -F “[: ]+” ‘{print $4}’192.168.20.130
sed方法4：ifconfig eth0|sed -n ‘/inet addr/p’|sed -r ‘s#^.ddr:(.)Bc.*$##g’192.168.20.130
```



## 每晚12 点备份/var/www/html 目录下文件到/data 

```shell
$ cat a.sh
#!/bin/bash
cd /var/www/ && /bin/tar zcf /data/html-date +%m-%d%H.tar.gz html/

$ crontab –e
00 00 * * * /bin/sh /root/a.sh
```



## DNS 原理

相信大家可能知道 windows 或者 linux 系统层面的/etc/hosts 文件是：IP 地址与域名的对应关系。

我们一般访问网站的步骤：

打开网页-------输入网址 www.sb.com-----查看本地的 DNS 库是否存在该网站域名与对应 ip 地址的对应关系

接下来分为两种情况：

① 本地存在该网站域名相对应的 IP 地址，然后我们直接根据本地缓存的 DNS 进行解析，然后访问

该域名对应的 IP 地址，然后进行 TCP 的三次握手,进行与网站的连接，当然我们访问网站完毕之

后，我们又进行了四次挥手，然后断开连接。（后面详细解释 TCP 的三次握手与四次挥手） 

② 本地不存在该网站域名与 IP 地址的对应关系，然后我们本地的 DNS 系统，也就是 LDNS（简称

local DNS）；开始从 DNS 系统的根进行请求对 www.sb.com 域名的解析，并且针对 DNS 系统的

各个阶层进行查找，进行一级一级的查找，最终会找到 www.sb.com 这个域名，当然 DNS 系统里

这个域名的进行授权的 DNS 服务器正是我们企业购买的 DNS 服务器，反之，没有该域名相应的

解析授权的 DNS 服务器，也就表明该网站没有搭建成功。

 ![1590653695245](assets/1590653695245.png)

总结： 

进行本地 DNS 查找以及授权 DNS 服务器的查找，获得 IP 地址，并且加载本地 DNS 的缓存 

进行建立 TCP 连接的过程（三次握手），发送 http 报文以及请求报文的细节，web 服务器的响应并且处理客户端的 

请求，关闭 TCP 连接（四次挥手）； 

 

## Linux常用快捷键操作

| 快捷键                 | 功能说明                                                     |
| ---------------------- | ------------------------------------------------------------ |
| 最有用快捷键           |                                                              |
| tab                    | 命令或路径等的补全键，Linux最有用快捷键*                     |
| 移动光标快捷键         |                                                              |
| Ctrl+a                 | 光标回到命令行首*                                            |
| Ctrl+e                 | 光标回到命令行尾*                                            |
| Ctrl+f                 | 光标向右移动一个字符（相当于方向键右键）                     |
| Ctrl+b                 | 光标向左移动一个字符（相当于方向键左键）                     |
| 剪切、粘贴、清除快捷键 |                                                              |
| Ctrl+Insert            | 复制命令行内容*                                              |
| Shift+Insert           | 粘贴命令行内容*                                              |
| Ctrl+k                 | 剪切（删除）光标处到行尾的字符*                              |
| Ctrl+u                 | 剪切（删除）光标处到行首的字符*                              |
| Ctrl+w                 | 剪切（删除）光标前的一个单词                                 |
| Ctrl+y                 | 粘贴Ctrl+u，Ctrl+k，Ctrl+w删除的文本                         |
| Ctrl+c                 | 中断终端正在执行的任务或者删除整行*                          |
| Ctrl+h                 | 删除光标所在处的前一个字符（相当于退格键）                   |
| 重复执行命令快捷键     |                                                              |
| Ctrl+d                 | 退出当前Shell命令行*                                         |
| Ctrl+r                 | 搜索命令行使用过的历史命令记录*                              |
| Ctrl+g                 | 从执行Ctrl+r的搜索历史命令模式退出                           |
| Esc+.(点)              | 获取上一条命令的最后的部分（空格分隔）*                      |
| 控制快捷键             |                                                              |
| Ctrl+l                 | 清除屏幕所有内容，并在屏幕最上面开始一个新行，等同clear命令* |
| Ctrl+s                 | 锁定终端，使之无法输入内容                                   |
| Ctrl+q                 | 解锁执行Ctrl+s的锁定状态                                     |
| Ctrl+z                 | 暂停执行在终端运行的任务*                                    |
| !号开头的快捷命令      |                                                              |
| !!                     | 执行上一条命令                                               |
| !pw                    | 执行最近以pw开头的命令*                                      |
| !pw:p                  | 仅打印最近pw开头的命令，但不执行                             |
| !num                   | 执行历史命令列表的第num(数字)条命令*                         |
| !$                     | 上一条命令的最后一个参数，相当于Esc+.(点)                    |
| ESC相关                |                                                              |
| Esc+.(点)              | 获取上一条命令的最后的部分（空格分隔）*                      |
| Esc+b                  | 移动到当前单词的开头                                         |
| Esc+f                  | 移动到当前单词的结尾                                         |
| Esc+t                  | 颠倒光标所在处及其相邻单词的位置                             |



## 统计nginx访问日志中前十的ip

```
awk '{print $1}' access.log| uniq -c | sort -rn | head -10
```





## tomcat 优化

安全优化
配置文件里面的指定的开启服务，关闭服务的端口。
① 关闭端口保护 8005 SHUTDOWN
② ajp 连接端口保护（阿帕奇与 java 直接连接的端口） 8009 注释
③ 禁用管理端（也就是网页的三个选项）
④ 降权启动 （降低用户权限启动，也就是以普通用户的身份去运行 tomcat）

性能优化
tomcat 性能取决于你的内存大小
提供四种办法：
① 上策：优化代码
② 中策：jvm 优化机制 垃圾回收机制 把不需要的内存回收
③ 优化 jvm--优化垃圾回收策略
④ 优化 catalina.sh 配置文件。

内存优化
Tomcat内存优化主要是对 tomcat 启动参数优化，我们可以在 tomcat 的启动脚本 catalina.sh 中设置 java_OPTS 参数。

并发优化
调整连接器connector的并发处理能力；在Tomcat 配置文件 server.xml 中的

缓存压缩优化
打开tomcat的压缩功能；tomcat的压缩优化就是将返回的html页面等内容经过压缩，压缩成gzip格式之后，发送给浏览器，浏览器在本地解压缩的过程。



## LVS负载均衡（LVS简介、三种工作模式、十种调度算法）

**一、LVS简介**

​       LVS（Linux Virtual Server）即Linux虚拟服务器，是由章文嵩博士主导的开源负载均衡项目，目前LVS已经被集成到Linux内核模块中。该项目在Linux内核中实现了基于IP的数据请求负载均衡调度方案，其体系结构如图1所示，终端互联网用户从外部访问公司的外部负载均衡服务器，终端用户的Web请求会发送给LVS调度器，调度器根据自己预设的算法决定将该请求发送给后端的某台Web服务器，比如，轮询算法可以将外部的请求平均分发给后端的所有服务器，终端用户访问LVS调度器虽然会被转发到后端真实的服务器，但如果真实服务器连接的是相同的存储，提供的服务也是相同的服务，最终用户不管是访问哪台真实服务器，得到的服务内容都是一样的，整个集群对用户而言都是透明的。最后根据LVS工作模式的不同，真实服务器会选择不同的方式将用户需要的数据发送到终端用户，LVS工作模式分为NAT模式、TUN模式、以及DR模式。

![img](assets/clipboard-1585570640069.png)





**二、三种工作模式的解析。**

**1、基于NAT的LVS模式负载均衡**

​      NAT（Network Address Translation）即网络地址转换，其作用是通过数据报头的修改，使得位于企业内部的私有IP地址可以访问外网，以及外部用用户可以访问位于公司内部的私有IP主机。VS/NAT工作模式拓扑结构如图2所示，LVS负载调度器可以使用两块网卡配置不同的IP地址，eth0设置为私钥IP与内部网络通过交换设备相互连接，eth1设备为外网IP与外部网络联通。

​       第一步，用户通过互联网DNS服务器解析到公司负载均衡设备上面的外网地址，相对于真实服务器而言，LVS外网IP又称VIP（Virtual IP Address），用户通过访问VIP，即可连接后端的真实服务器（Real Server），而这一切对用户而言都是透明的，用户以为自己访问的就是真实服务器，但他并不知道自己访问的VIP仅仅是一个调度器，也不清楚后端的真实服务器到底在哪里、有多少真实服务器。

   第二步，用户将请求发送至124.126.147.168，此时LVS将根据预设的算法选择后端的一台真实服务器（192.168.0.1~192.168.0.3），将数据请求包转发给真实服务器，并且在转发之前LVS会修改数据包中的目标地址以及目标端口，目标地址与目标端口将被修改为选出的真实服务器IP地址以及相应的端口。

​    第三步，真实的服务器将响应数据包返回给LVS调度器，调度器在得到响应的数据包后会将源地址和源端口修改为VIP及调度器相应的端口，修改完成后，由调度器将响应数据包发送回终端用户，另外，由于LVS调度器有一个连接Hash表，该表中会记录连接请求及转发信息，当同一个连接的下一个数据包发送给调度器时，从该Hash表中可以直接找到之前的连接记录，并根据记录信息选出相同的真实服务器及端口信息。

![img](assets/clipboard-1585570640070.png)



**2、基于TUN的LVS负载均衡**

​       在LVS（NAT）模式的集群环境中，由于所有的数据请求及响应的数据包都需要经过LVS调度器转发，如果后端服务器的数量大于10台，则调度器就会成为整个集群环境的瓶颈。我们知道，数据请求包往往远小于响应数据包的大小。因为响应数据包中包含有客户需要的具体数据，所以LVS（TUN）的思路就是将请求与响应数据分离，让调度器仅处理数据请求，而让真实服务器响应数据包直接返回给客户端。VS/TUN工作模式拓扑结构如图3所示。其中，IP隧道（IP tunning）是一种数据包封装技术，它可以将原始数据包封装并添加新的包头（内容包括新的源地址及端口、目标地址及端口），从而实现将一个目标为调度器的VIP地址的数据包封装，通过隧道转发给后端的真实服务器（Real Server），通过将客户端发往调度器的原始数据包封装，并在其基础上添加新的数据包头（修改目标地址为调度器选择出来的真实服务器的IP地址及对应端口），LVS（TUN）模式要求真实服务器可以直接与外部网络连接，真实服务器在收到请求数据包后直接给客户端主机响应数据。

![img](assets/clipboard-1585570640070.png)

**3、基于DR的LVS负载均衡**

​	在LVS（TUN）模式下，由于需要在LVS调度器与真实服务器之间创建隧道连接，这同样会增加服务器的负担。与LVS（TUN）类似，DR模式也叫直接路由模式，其体系结构如图4所示，该模式中LVS依然仅承担数据的入站请求以及根据算法选出合理的真实服务器，最终由后端真实服务器负责将响应数据包发送返回给客户端。与隧道模式不同的是，直接路由模式（DR模式）要求调度器与后端服务器必须在同一个局域网内，VIP地址需要在调度器与后端所有的服务器间共享，因为最终的真实服务器给客户端回应数据包时需要设置源IP为VIP地址，目标IP为客户端IP，这样客户端访问的是调度器的VIP地址，回应的源地址也依然是该VIP地址（真实服务器上的VIP），客户端是感觉不到后端服务器存在的。由于多台计算机都设置了同样一个VIP地址，所以在直接路由模式中要求调度器的VIP地址是对外可见的，客户端需要将请求数据包发送到调度器主机，而所有的真实服务器的VIP地址必须配置在Non-ARP的网络设备上，也就是该网络设备并不会向外广播自己的MAC及对应的IP地址，真实服务器的VIP对外界是不可见的，但真实服务器却可以接受目标地址VIP的网络请求，并在回应数据包时将源地址设置为该VIP地址。调度器根据算法在选出真实服务器后，在不修改数据报文的情况下，将数据帧的MAC地址修改为选出的真实服务器的MAC地址，通过交换机将该数据帧发给真实服务器。整个过程中，真实服务器的VIP不需要对外界可见。

![img](assets/clipboard-1585570640070.png)

**三、LVS负载均衡调度算法**

​      根据前面的介绍，我们了解了LVS的三种工作模式，但不管实际环境中采用的是哪种模式，调度算法进行调度的策略与算法都是LVS的核心技术，LVS在内核中主要实现了一下十种调度算法。

**1.轮询调度**

轮询调度（Round Robin 简称'RR'）算法就是按依次循环的方式将请求调度到不同的服务器上，该算法最大的特点就是实现简单。轮询算法假设所有的服务器处理请求的能力都一样的，调度器会将所有的请求平均分配给每个真实服务器。

**2.加权轮询调度**

加权轮询（Weight Round Robin 简称'WRR'）算法主要是对轮询算法的一种优化与补充，LVS会考虑每台服务器的性能，并给每台服务器添加一个权值，如果服务器A的权值为1，服务器B的权值为2，则调度器调度到服务器B的请求会是服务器A的两倍。权值越高的服务器，处理的请求越多。

**3.最小连接调度**

最小连接调度（Least Connections 简称'LC'）算法是把新的连接请求分配到当前连接数最小的服务器。最小连接调度是一种动态的调度算法，它通过服务器当前活跃的连接数来估计服务器的情况。调度器需要记录各个服务器已建立连接的数目，当一个请求被调度到某台服务器，其连接数加1；当连接中断或者超时，其连接数减1。

（集群系统的真实服务器具有相近的系统性能，采用最小连接调度算法可以比较好地均衡负载。)

**4.加权最小连接调度**

加权最少连接（Weight Least Connections 简称'WLC'）算法是最小连接调度的超集，各个服务器相应的权值表示其处理性能。服务器的缺省权值为1，系统管理员可以动态地设置服务器的权值。加权最小连接调度在调度新连接时尽可能使服务器的已建立连接数和其权值成比例。调度器可以自动问询真实服务器的负载情况，并动态地调整其权值。

**5.基于局部的最少连接**

基于局部的最少连接调度（Locality-Based Least Connections 简称'LBLC'）算法是针对请求报文的目标IP地址的 负载均衡调度，目前主要用于Cache集群系统，因为在Cache集群客户请求报文的目标IP地址是变化的。这里假设任何后端服务器都可以处理任一请求，算法的设计目标是在服务器的负载基本平衡情况下，将相同目标IP地址的请求调度到同一台服务器，来提高各台服务器的访问局部性和Cache命中率，从而提升整个集群系统的处理能力。LBLC调度算法先根据请求的目标IP地址找出该目标IP地址最近使用的服务器，若该服务器是可用的且没有超载，将请求发送到该服务器；若服务器不存在，或者该服务器超载且有服务器处于一半的工作负载，则使用'最少连接'的原则选出一个可用的服务器，将请求发送到服务器。

**6.带复制的基于局部性的最少连接**

带复制的基于局部性的最少连接（Locality-Based Least Connections with Replication  简称'LBLCR'）算法也是针对目标IP地址的负载均衡，目前主要用于Cache集群系统，它与LBLC算法不同之处是它要维护从一个目标IP地址到一组服务器的映射，而LBLC算法维护从一个目标IP地址到一台服务器的映射。按'最小连接'原则从该服务器组中选出一一台服务器，若服务器没有超载，将请求发送到该服务器；若服务器超载，则按'最小连接'原则从整个集群中选出一台服务器，将该服务器加入到这个服务器组中，将请求发送到该服务器。同时，当该服务器组有一段时间没有被修改，将最忙的服务器从服务器组中删除，以降低复制的程度。

**7.目标地址散列调度**

目标地址散列调度（Destination Hashing 简称'DH'）算法先根据请求的目标IP地址，作为散列键（Hash Key）从静态分配的散列表找出对应的服务器，若该服务器是可用的且并未超载，将请求发送到该服务器，否则返回空。

**8.源地址散列调度U**

源地址散列调度（Source Hashing  简称'SH'）算法先根据请求的源IP地址，作为散列键（Hash Key）从静态分配的散列表找出对应的服务器，若该服务器是可用的且并未超载，将请求发送到该服务器，否则返回空。它采用的散列函数与目标地址散列调度算法的相同，它的算法流程与目标地址散列调度算法的基本相似。

**9.最短的期望的延迟**

最短的期望的延迟调度（Shortest Expected Delay 简称'SED'）算法基于WLC算法。举个例子吧，ABC三台服务器的权重分别为1、2、3 。那么如果使用WLC算法的话一个新请求进入时它可能会分给ABC中的任意一个。使用SED算法后会进行一个运算

A：（1+1）/1=2   B：（1+2）/2=3/2   C：（1+3）/3=4/3   就把请求交给得出运算结果最小的服务器。

**10.最少队列调度**

最少队列调度（Never Queue 简称'NQ'）算法，无需队列。如果有realserver的连接数等于0就直接分配过去，不需要在进行SED运算。







## RabbitMQ是什么

RabbitMQ也就是消息队列中间件，消息中间件是在消息的传息过程中保存消息的容器
消息中间件再将消息从它的源中到它的目标中标时充当中间人的作用
队列的主要目的是提供路由并保证消息的传递；如果发送消息时接收者不可用
消息队列不会保留消息，直到可以成功地传递为止，当然，消息队列保存消息也是有期限地



## 优化Linux系统

1. 不用root，添加普通用户，通过sudo授权管理

2. 更改默认的远程连接SSH服务端口及禁止root用户远程连接

3. 定时自动更新服务器时间

4. 配置国内yum源

5. 关闭selinux及iptables（iptables工作场景如果有外网IP一定要打开，高并发除外）

6. 调整文件描述符的数量

7. 精简开机启动服务（crond rsyslog network sshd）

8. 内核参数优化（/etc/sysctl.conf）

9. 更改字符集，支持中文，但建议还是用英文字符集，防止乱码

10. 锁定关键系统文件
11. 清空/etc/issue，去除系统及内核版本登录前的屏幕显示



## ELK介绍

**1.ELK分别表示什么？**

三个开源软件 elasticsearch logstash kibana

**2.elasticsearch的特点是什么**

elasticsearch，基于lucene开发，隐藏了复杂性，提供了简单易用的restful api接口，Java api 接口（以及其他语言的api接口）Elasticsearch是当前主流的分布式大数据存储和搜索引擎，可以为用户提供强大的全文本检索能力，广泛应用于日志检索，全站搜索等领域。Logstash作为Elasicsearch常用的实时数据采集引擎，可以采集来自不同数据源的数据，并对数据进行处理后输出到多种输出源，是Elastic Stack 的重要组成部分。

elasticsearch基本特点：

①：分布式的文档存储引擎

②：分布式的搜索引擎和分析引擎

③：分布式，支持PB级数据

**3.kibana的特点和作用是什么**

所有类型的数据集中处理

不同模式和格式数据的正常化

自定义日志格式的迅速扩展

为自定义数据源轻松添加插件

提供web页面进行可视化展示

**4.logstash的特点和作用是什么**

Logstash 能够动态地采集、转换和传输数据，不受格式或复杂度的影响。利用 Grok 从非结构化数据中派生出结构，从 IP 地址解码出地理坐标，匿名化或排除敏感字段，并简化整体处理过程。

Logstash 是开源的服务器端数据处理管道，能够同时 从多个来源采集数据、转换数据，然后将数据发送到您最喜欢的 “存储库” 中。（我们的存储库当然是 Elasticsearch。）

可伸缩性 可过滤 作用就是一款强大的数据处理，可实现数据传输，格式处理，格式化输出，还有强大的插件功能，常用于日志处理

**5.ELK能做什么？**

ELK组件在海量日志系统的运维中，可用于解决：

\- 分布式日志数据集中式查询和管理

\- 系统监控，包含系统硬件和应用各个组件的监控

\- 故障排查

\- 安全信息和事件管理

\- 报表功能

**6.ELK在你使用的过程中主要用来做什么？**

分析系统日志，访问日志，应用日志，分析数据

**7.elasticSearch 中的集群，节点，文档，类型和索引是什么**

集群：一个集群是由一个多个组成的集合，集群上的节点将会存储数据，并提供跨界点的所用和搜索过滤

节点：一个节点就是一个elasticsearch服务，可以是现存书数据，索引并且搜索的功能，和集群一样，每一个节点都有唯一的名称为标识

文档：elaticsearch是面向文档这意味着特可以存储关于整个对象或文档，然而它不仅仅是为存储，还会索

引每个文档的内容是指可以被搜索

索引：在elasticsearch中存储数据的行为较为索引

类型：文档属于一种类型而这类型存在于索引中，我们可以画一些简单的对比图来比传统关系数据库





## linux中的软硬链接

1.5.1 链接的概念

在Linux系统中，链接分为两种：一种为硬链接（Hard Link），另一种为软链接（Symbolic Link or Soft Link）。链接由ln命令创建，默认不带参数的情况下，执行ln命令创建的是硬链接，# ln -s命令创建的是软链接。创建命令如下：

硬链接：# ln  源文件  创建的目标文件

软链接：# ln  -s  源文件  创建的目标文件

 

1.5.2 硬链接

硬链接通过索引节点（inode）来进行链接。**在Linux文件系统中，多个文件名指向同一个索引节点（inode），这是被允许的，这种情况被称为文件的硬链接。硬链接的作用之一，就是允许一个文件拥有多个有效路径（多个入口），这样用户可以建立硬链接到重要的文件，防止“误删”源数据。**只要文件还存在一个以上的硬链接，删除其中的一个硬链接（删除了该文件的链接指向），不影响索引节点和其他的链接，即数据文件实体并未被删除。只有当最后一个链接被删除后，此时，如果有新的数据要存储到硬盘上，或系统通过类似fsck检查磁盘时，被删除文件的数据块及目录的链接才会被释放，空间被新的数据覆盖。**也就是说，在Linux系统中，**删除静态文件（没有进程调用，目录也是文件）的条件是与之相关的所有硬链接文件均被删除，文件才会被删除。

 

**对硬链接有如下限制：** 

不能对目录文件做硬链接。 

不能在不同的文件系统之间做硬链接。

就是说，链接文件和被链接文件必须位于同一个文件系统中。

 

1.5.3 软链接

软链接（Soft Link）也叫符号链接（Symbolic Link）。Linux系统里的软链接就相当于Windows里的快捷方式。软链接可以理解为一个文本文件，这个文件中包含有软链接指向另一源文件的位置信息内容。因此，通过软链接可以快速定位到软链接所指向的源文件实体。













## zabbix分布式监控

![1585571215014](assets/1585571215014.png)

**思路：**

**Zabbix-agent 端======》zabbix-proxy======》zabbix-server 端**

**所以：**

**Zabbix-agent 的服务端的 ip 为 zabbix-proxy 的 IP 地址**

**Zabbix-proxy 的服务端的 ip 为 zabbix-server 的 IP 地址**

**zabbix有哪些监控方式，主动还是被动(主被动模式都是相对于zabbix-agent来说的)**

**主动**是zabbix-agent主动获取的主机监控项列表，并主动将监控项内需要检测的数据提交给zabbix-server或zabbix-proxy

**被动**是zabbix-server向zabbix-agent请求获取监控项的数据，zabbix-agent返回数据





























## 一条命令计算1+2..+10,并用bc计算

```shell
方法一
echo `seq -s '+' 10`|bc = echo $((`seq -s '+' 10`))
方法二:
echo {1..10}|tr " " "+"|bc
```





















## Centos7进入单用户模式

当我们设置用户密码时，有可能会忘记，这时如何登陆呢，单用户模式就可以

首先我们进入开机界面，按e进行选择

![1358878-20180505014619044-1253959148](assets/1358878-20180505014619044-1253959148.png)

找到linux16这一行，

![1358878-20180505014643927-962476190](assets/1358878-20180505014643927-962476190.png)

然后找到图中红线标注的该行，将ro修改为rw并在行尾添加 init=/bin/sh

![1586695057758](assets/1586695057758.png)

按住Ctrl+x执行

可以进入单用户模式

![1358878-20180505014927763-1661480958](assets/1358878-20180505014927763-1661480958.png)

如图所示，我们还可以修改密码，默认修改root密码，也可以修改其他用户的密码passwd junjind

执行exec  /sbin/init 即可退出单用户模式

![1358878-20180505015129387-1417846437](assets/1358878-20180505015129387-1417846437.png)



## Centos linux 最大文件数

**问题描述：**

在做linux服务器程序的时候，当流量上来，linux服务器的默认单进程的文件打开数肯定是不够的，一般非root用户进程默认只有1024个文件打开权限，所有对文件的操作，对网络的操作，在linux下都作为一个文件打开，所以在并发量大的时候，这个限制很快就达到了。一旦达到这个限制，应用程序就会报一个：too many open files的错误。解决这个问题就需要增大这个限制。

在Bash中有个ulimit命令，提供了对Shell及该Shell启动的进程的可用资源控制。主要包括打开文件描述符数量、用户的最大进程数量、coredump文件的大小等。

在CentOS5/6等版本中，资源限制的配置可以在/etc/security/limits.conf设置，针对root/user等各个用户或者*代表所有用户来设置。 当然，/etc/security/limits.d/中可以配置，系统是先加载limits.conf然后按照英文字母顺序加载limits.d目录下的配置文件，后加载配置覆盖之前的配置。



下面是我在网上找到的，而且也已经应用在实际服务器的运维上：

```bash
linux默认下open files 是1024，首先看下系统现有的设置

[root@lpmaster ~]# ulimit -a

core file size (blocks, -c) 0 ##设定core文件的最大值

data seg size (kbytes, -d) unlimited ##程序数据节区的最大值

scheduling priority (-e) 0 ##

file size (blocks, -f) unlimited ##shell所能建立的最大文件

pending signals (-i) 71680

max locked memory (kbytes, -l) 32 ##设置在内存中锁定进程的最大值.

max memory size (kbytes, -m) unlimited ##设置可以使用的常驻内存的最大值.

open files (-n) 1024 ##设置内核可以同时打开的文件描述符的最大值.单位:n

pipe size (512 bytes, -p) 8 ##设置管道缓冲区的最大值

POSIX message queues (bytes, -q) 819200

real-time priority (-r) 0

stack size (kbytes, -s) 10240 ##设置堆栈的最大值.单位:kbytes

cpu time (seconds, -t) unlimited ##设置CPU使用时间的最大上限.单位:seconds

max user processes (-u) 71680 ##用户最多可开启的程序数目。

virtual memory (kbytes, -v) unlimited ##指定可使用的虚拟内存上限，单位为KB。

file locks (-x) unlimited
参数介绍：
　-H 设置硬件资源限制.
　-S 设置软件资源限制.
　-a 显示当前所有的资源限制.
　-c size:设置core文件的最大值.单位:blocks
　-d size:设置数据段的最大值.单位:kbytes
　-f size:设置创建文件的最大值.单位:blocks
　-l size:设置在内存中锁定进程的最大值.单位:kbytes
　-m size:设置可以使用的常驻内存的最大值.单位:kbytes
  -n size:设置内核可以同时打开的文件描述符的最大值.单位:n
　-p size:设置管道缓冲区的最大值.单位:kbytes
　-s size:设置堆栈的最大值.单位:kbytes
　-t size:设置CPU使用时间的最大上限.单位:seconds
　-v size:设置虚拟内存的最大值.单位:kbytes


当看到open files 是1024，针对我的应用 是完全不够用的，现在进行修改

[root@lpmaster ~]# ulimit -n 65535 ##设置 open files 打开的文件数65535
[root@lpmaster ~]# ulimit -n #查看现在系统open files

65535

或者用另一种方法修改

vim 打开 /etc/security/limits.conf，增加：
　　* soft nofile 65535
　　* hard nofile 65535

这行设置了每个用户的默认打开文件数为2048。注意"nofile"项有两个可能的限制措施。就是项下的hard和soft。要使修改过得最大打开文件数生效，必须对这两种限制进行设定。 如果使用"-"字符设定, 则hard和soft设定会同时被设定。

硬限制表明soft限制中所能设定的最大值。 soft限制指的是当前系统生效的设置值。 hard限制值可以被普通用户降低。但是不能增加。 soft限制不能设置的比hard限制更高。 只有root用户才能够增加hard限制值。

在对open files 修改最大值是，也可以检查/proc/sys/fs/file-max文件来确认系统最大打开文件数的限制，另外还有一个，/proc/sys/fs/file-nr只读，可以看到整个系统目前使用的文件句柄数量

也可以一般在启动应用的时候先执行ulimit -HSn 65535，省得每个应用启动都要执行ulimit -HSn 65535

所以我一般写入到/etc/rc.local ,这样重启的时候默认设置
```













 

## TCP 的三次握手与四次挥手原理

 **三次握手**

![1585299113983](assets/1585299113983.png)

**CLOSED 关闭状态：** 

为建立建立连接之前的起始点，在连接超时或者连接关闭的时候进入此状态，但是这并不是一个真正的状态，而是

这个状态图的假想起点和终点（便于我们思考与理解）。

**LISTEN 监听状态：**

服务器 server 端等待连接的状态。服务器经过 socket，bind，listen 函数之后进入此状态，开始监听客户端发

过来的连接请求。此称为应用程序被动打开（等待客户端的连接请求）。

**SYN_SENT 状态：**

第一次握手发生阶段，客户端发起连接。客户端调用 connect，发送 SYN 给服务器端，然后客户端进入 SYN_SENT状态，等待服务端的确认（三次握手中的第二个报文）。如果服务器端不能连接，则客户端直接进入 CLOSED 状态。 

**SYN_RCVD 状态：**

第二次握手发生阶段，这里是服务器端接收到了客户端的 SYN 请求，此时服务端由 LISTEN 进入 SYN_RCVD 状态，同时服务器端回应一个 ACK，然后再发送一个 SYN 即 SYN+ACK 给客户端。

状态图中还描绘了这样一种情况，当客户端在发送 SYN 的同时也收到服务器端的 SYN 请求，即两个同时发起连接请求，那么客户端就会从 SYN_SENT 转换到 SYN_REVD 状态。

**ESTABLISHED 状态：**

第三次握手发生阶段，客户端接收到服务器端的 ACK 包（ACK，SYN）之后，也会发送一个 ACK 确认包，客户端进入 ESTABLISHED 状态，表明客户端这边已经准备好，但 TCP 需要两端都准备好才可以进行数据传输。服务器端收到客户端的 ACK 之后会从 SYN_RCVD 状态转移到 ESTABLISHED 状态，表明服务器端也准备好进行数据传输了。 

**总结：**

客户端和服务器端都变为 ESTABLISHED 状态，就可以进行数据的传输了；当然 ESTABLISHED 也可以说是一个数据传送状态。

**四次挥手**

![1585299158926](assets/1585299158926.png)

**FIN_WAIT_1 状态：**

第一次挥手 主动关闭的一方（执行主动关闭的一方既可以是客户端，也可以是服务器端，我们这里以客户端执行主动关闭为例子），终止连接时，发送 FIN 给对方，然后等待对方返回 ACK 。第一次挥手客户端就进入 fin_wait_1状态。

**CLOSE_WAIT 状态：**

接收到 FIN 之后，被动关闭的一方进入 close_wait 状态。进入该状态的具体动作是接收到客户端发来的 FIN，同时服务端对客户端发送 ACK。 CLOSE_WAIT 状态：可以理解为被动关闭的一方此时正在等待上层应用程序发出关闭连接指令。TCP 关闭是全双工过程，这里客户端执行了主动关闭，被动方服务器端接收到 FIN 后也需要调用 close 关闭，这个 CLOSE_WAIT 就是处于这个状态，等待关闭的请求方发送 FIN，发送了 FIN 则进入 LAST_ACK 状态。

**FIN_WAIT_2 状态：**

主动端（这里是客户端）先执行主动关闭发送 FIN，然后接收到被动方（这里是服务端）返回的 ACK 后进入此状态。

**LAST_ACK 状态：**

被动方（服务器端）发起关闭请求，发送 FIN 给对方，进入此状态，同时在接收到 ACK 时进入 CLOSED 状态。

**CLOSING 状态：**

两边同时发起关闭请求时（即主动方发送 FIN，等待被动方返回 ACK，同时被动方也发送了 FIN；主动方接收到了FIN 之后，发送 ACK 给被动方），主动方会由 FIN_WAIT_1 进入此状态，等待被动方返回 ACK。

**TIME_WAIT 状态：**

从状态变迁图会看到，四次挥手操作最后都会经过这样一个状态然后进入 CLOSED 状态。共有三个状态会进入该状态

**由 CLOSEING 状态进入：**

同时发起关闭情况下，当主动端接收到 ACK 后，进入此状态，实际上这里的同时是这样的情况：客户端发起关闭请求，发送 FIN 之后等待服务器端回应 ACK，但此时服务器端同时也发起关闭请求，也发送了 FIN，并且被客户端先于 ACK 接收到。

**由 FIN_WAIT_1 进入：**

发起关闭后，发送了 FIN，等待 ACK 的时候，正好被动方（服务器端）也发起关闭请求，发送了 FIN，这时客户端接收到了先前 ACK，也收到了对方的 FIN，然后发送 ACK（对对方 FIN 的回应），与 CLOSING 进入的状态不同的是接收到 FIN 和 ACK 的先后顺序。

**由 FIN_WAIT_2 进入：**

这是不同时的情况，主动方在完成自身发起的主动关闭请求后，接收到了对方发送过来的 FIN，然后回应 ACK。

## TCP 十一种状态转移总结

![1585299339581](assets/1585299339581.png)

## TCP/IP的七层模型

应用层 (Application)：网络服务与最终用户的一个接口。
协议有：HTTP FTP TFTP SMTP SNMP DNS TELNET HTTPS POP3 DHCP

表示层（Presentation Layer）：数据的表示、安全、压缩。（在五层模型里面已经合并到了应用层）
格式有，JPEG、ASCll、DECOIC、加密格式等

会话层（Session Layer）：建立、管理、终止会话。（在五层模型里面已经合并到了应用层）
对应主机进程，指本地主机与远程主机正在进行的会话

传输层 (Transport)：定义传输数据的协议端口号，以及流控和差错校验。
协议有：TCP UDP，数据包一旦离开网卡即进入网络传输层

网络层 (Network)：进行逻辑地址寻址，实现不同网络之间的路径选择。
协议有：ICMP IGMP IP（IPV4 IPV6） ARP RARP

数据链路层 (Link)：建立逻辑连接、进行硬件地址寻址、差错校验等功能。（由底层网络定义协议）
将比特组合成字节进而组合成帧，用MAC地址访问介质，错误发现但不能纠正

物理层（Physical Layer）：是计算机网络OSI模型中最低的一层

物理层规定:为传输数据所需要的物理链路创建、维持、拆除
而提供具有机械的，电子的，功能的和规范的特性

简单的说，物理层确保原始的数据可在各种物理媒体上传输。局域网与广域网皆属第1、2层

物理层是OSI的第一层，它虽然处于最底层，却是整个开放系统的基础
物理层为设备之间的数据通信提供传输媒体及互连设备，为数据传输提供可靠的环境
如果您想要用尽量少的词来记住这个第一层，那就是“信号和介质”

 ![img](assets/clipboard.png)



## 用tcpdump抓取主机192.168.1.1，端口80的数据，并将输出保存到tcpdump.log

```shell
tcpdump ‘host 192.168.1.1 and port 80’ > tcpdump.log
```

## 将IP 为192.168.2.1的80 端口的请求转发到8080

```shell
iptables -A PREROUTING -d 192.168.2.1 -p tcp -m tcp -dport 80 -j DNAT-to-destination 192.168.2.1:8080
```



## 用tcpdump嗅探80端口的访问看看谁最高

```shell
tcpdump -i eth0 -tnn dst port 80 -c 1000 | awk -F"." '{print $1.$2.$3.$4}'| sort | uniq -c | sort -nr |head -20
```



## 查看TCP连接的所有状态

```
netstat -n | awk '/^tcp/ {++S[$NF]} END {for(a in S) print a, S[a]}'
```

还有ulimit -n 查看linux系统打开最大的文件描述符，这里默认1024
不修改这里web服务器修改再大也没用，若要用就修改很几个办法，这里说其中一个：
修改/etc/security/limits.conf

- soft nofile 10240

- hard nofile 10240

  重启后生效





## TIME_WAIT过多或者CLOSE_WAIT过多的状态

**TIME_WAIT过多或者CLOSE_WAIT过多的状态**

**1 起因**

线上服务器nginx日志运行一段时间后，会报如下错误：

```
1024 worker_connections are not enough 
```

一般做法是修改worker_connections。 

但实际上：

该服务是用于时间比较短的连接里，并且一天最多才4000个请求。不可能会耗尽worker_connections。 

除非每次连接都没有释放对应的连接。 

```shell
shell>netstat -n | awk ‘/^tcp/ {++S[$NF]} END {for(a in S) print a, S[a]}’ CLOSE_WAIT 802 ESTABLISHED 106 

shell>lsof -n | grep “nginx对应的一个进程id” 
MvLogServ 31125 mv 111u IPv4 76653578 0t0 TCP 10.1.138.60:8996->10.1.138.60:51977 (CLOSE_WAIT) MvLogServ 31125 mv 112u IPv4 76659698 0t0 TCP 10.1.138.60:8996->10.1.138.60:52015 (CLOSE_WAIT) MvLogServ 31125 mv 113u IPv4 76662836 0t0 TCP 10.1.138.60:8996->10.1.138.60:52042 (CLOSE_WAIT) MvLogServ 31125 mv 114u IPv4 76663435 0t0 TCP 10.1.138.60:8996->10.1.138.60:52051 (CLOSE_WAIT) MvLogServ 31125 mv 115u IPv4 76682134 0t0 TCP 10.1.138.60:8996->10.1.138.60:52136 (CLOSE_WAIT) MvLogServ 31125 mv 116u IPv4 76685095 0t0 TCP 10.1.138.60:8996->10.1.138.60:52159 (CLOSE_WAIT) 
```

**TIME_WAIT：表示主动关闭，通过优化系统内核参数可容易解决。** 

**CLOSE_WAIT：表示被动关闭，需要从程序本身出发。** 

**ESTABLISHED：表示正在通信** 

则可知：nginx：CLOSE_WAIT过多的状态

**2 解决**

**2.1 TIME_WAIT 通过优化系统内核参数可容易解决**

TIME_WAIT大量产生很多通常都发生在实际应用环境中。 

TIME_WAIT产生的原因：在通讯过程中A主动关闭造成的， 在A发送了最后一个FIN包后，系统会等待 Double时间的MSL(Max Segment Lifetime)

【注：按不同的操作系统有不同时间】用于等待接受B发送过来的FIN_ACK和FIN， 

这段时间A的对应的socket的fd是不能够重新利用的， 

这样在大量的**短连接高并发服务**中，会出现TIME_WAIT过多的现象。

解决方案： 

调整TIME_WAIT超时时间 

```shell
vi /etc/sysctl.conf  

net.ipv4.tcp_syncookies = 1 
#开启SYN Cookies,当出现SYN等待队列溢出时，启用cookies来处理，可防范少量SYN攻击，默认为0，表示关闭  

net.ipv4.tcp_tw_reuse = 1 
#允许将TIME-WAIT sockets重新用于新的TCP连接，默认为0，表示关闭

net.ipv4.tcp_tw_recycle = 1 
#表示开启TCP连接中TIME-WAIT sockets的快速回收，默认为0，表示关闭 #表示如果套接字由本端要求关闭。 #这个参数决定了它保持在FIN-WAIT-2状态的时间 
```

生效配置

```
/sbin/sysctl -p 
```



**2.2 CLOSE_WAIT 需要从程序本身出发**

**CLOSE_WAIT产生的原因是客户端B主动关闭， 服务器A收到FIN包，应用层却没有做出关闭操作引起的。** 

CLOSE_WAIT在Nginx上面的产生原因还是因为Nagle’s算法加Nginx本身EPOLL的ET触发模式导致。

ET出发模式在数据就绪的时候会触发一次回调操作，Nagle’s算法会累积TCP包，如果最后的数据包和FIN包被Nagle’s算法合并，会导致EPOLL的ET模式只触发一次。 

然而在应用层的SOCKET是读取返回0才代表链接关闭， 而读取这次合并的数据包时是不返回0的， 然后SOCKET以后都不会触发事件， 所以导致应用层没有关闭SOCKET， 从而产生大量的CLOSE_WAIT状态链接。 

关闭TCP_NODELAY，在Nginx配置中加上tcp_nodelay on; 

**3 总结**

- TIME_WAIT状态可以通过优化服务器参数得到解决。 

因为发生TIME_WAIT的情况是服务器自身可控的， 要么就是对方连接的异常，要么就是自己没有迅速回收资源， 总之不是由于自己程序错误导致的。

- CLOSE_WAIT需要通过程序本身。 

如果一直保持在CLOSE_WAIT状态，那么只有一种情况，就是在对方关闭连接之后服务器程序自己没有进一步发出ack信号。 

即在对方连接关闭之后，程序里没有检测到，或者程序没有关闭连接，于是这个资源就一直被程序占着。 

服务器对于程序抢占的资源没有主动回收的功能。只能修改程序本身。 



## DDOS介绍与防护

网站被DDOS也成为站长最头疼的事。在没有硬防的情况下,寻找软件代替是最直接的方法,比如用 iptables,但是iptables不能在自动屏蔽,只能手动屏蔽。

**一、什么是DDOS攻击？**

DDoS也就是分布式拒绝服务攻击。它使用与普通的拒绝服务攻击同样的方法,但是发起攻击的源是多个。通常攻击者使用下载的工具渗透无保护的主机,当获得该主机的适当的访问权限后,攻击者在主机中安装软件的服务或进程（以下简侈怔理）。这些代理保持睡眠状态,直到从它们的主控端得到指令,对指定的目标发起拒绝服务攻击。

**二、如何确认自己受到DDOS攻击？**

在系统上执行：

```shell
netstat -ntu | awk '{print $5}' | cut -d: -f1 | sort | uniq -c | sort -n
```

执行后,将会显示服务器上所有的每个IP多少个连接数。

以下是我自己用VPS测试的结果：

```shell
li88-99:~# netstat -ntu|awk '{print $5}' | cut -d: -f1 | sort | uniq -c | sort -n

1 114.226.9.132
1 174.129.237.157
1 58.60.118.142
1 Address
1 servers)
2 118.26.131.78
3 123.125.1.202
3 220.248.43.119
4 117.36.231.253
4 119.162.46.124
6 219.140.232.128
8 220.181.61.31

2311 67.215.242.196
```

每个IP几个、十几个或几十个连接数都还算比较正常,如果像上面成百上千肯定就不正常了。

**三、防范DDOS攻击的方法**

1.1 常规的一些防御方法

　　到目前为止,进行DDoS攻击的防御还是比较困难的。首先,这种攻击的特点是它利用了TCP/IP协议的漏洞,除非你不用TCP/IP,才有可能完全抵御住DDoS攻击。不过这不等于我们就没有办法阻挡DDoS攻击,我们可以尽力来减少DDoS的攻击。

下面就是一些防御方法:

- 确保服务器的系统文件是最新的版本,并及时更新系统补丁。
- 关闭不必要的服务。
- 限制同时打开的SYN半连接数目,缩短SYN半连接的time out 时间,限制SYN/ICMP流量

SYN攻击是利用TCP/IP协议3次握手的原理,发送大量的建立连接的网络包,但不实际建立连接,最终导致被攻击服务器的网络队列被占满,无法被正常用户访问。

Linux内核提供了若干SYN相关设置,使用命令：

```
sysctl -a | grep syn
```

看到：

```shell
net.ipv4.tcp_max_syn_backlog = 1024
net.ipv4.tcp_syncookies = 0
net.ipv4.tcp_synack_retries = 5
net.ipv4.tcp_syn_retries = 5
tcp_max_syn_backlog
```

调整上述设置的方法是：

增加SYN队列长度到2048：

```shell
sysctl -w net.ipv4.tcp_max_syn_backlog=2048
```

打开SYN COOKIE功能：

```shell
sysctl -w net.ipv4.tcp_syncookies=1
```

降低重试次数：

```shell
sysctl -w net.ipv4.tcp_synack_retries=3
sysctl -w net.ipv4.tcp_syn_retries=3
```

为了系统重启动时保持上述配置,可将上述命令加入到/etc/rc.d/rc.local文件中或者直接修改内核参数。

- 正确设置防火墙，禁止对主机的非开放服务的访问，限制特定IP地址的访问，启用防火墙的防DDoS的属性

- 认真检查网络设备和服务器系统的日志。只要日志出现漏洞或是时间变更,那这台机器就可能遭到了攻击。

- 限制在防火墙外与网络文件共享。这样会给黑客截取系统文件的机会,主机的信息暴露给黑客,无疑是给了对方入侵的机会。

- 充分利用网络设备保护网络资源

- 用足够的机器承受黑客攻击

- 检查访问者的来源









# NGINX相关

## 1、nginx和Apache的特点

**Apache 软件特点**

(1) Apache2.2 版本非常稳定强大，Apache2.4 版本性能更强

(2) Prefork 模式取消了进程创建开销，性能很高

(3) 处理动态业务数据时，因关联到后端的引擎和数据库，瓶颈不在 Apache 上

(4) 高并发时消耗系统资源相对多一些

(5) 基于传统的 select 模型，高并发能力有限

(6) 支持扩展库，可通过 DSO、apxs 方法编译安装额外的插件功能，不需要重新编译 Apache

(7) 功能多，更稳定，更安全，插件也多

(8) 市场份额在逐渐递减

 

**nginx 软件的特点**

支持高并发：能支持几万并发连接（特别是静态小文件业务环境）

资源消耗少：在 3 万并发连接下，开启 10 个 Nginx 线程消耗的内存不到 200MB、进程占用系统资源比较低

不支持类似 Apache 的 DSO 模式，扩展库必须编译进主程序（缺点）

支持 web、反向 proxy、cache 三大重点功能，并且都很优秀

可以做 HTTP 反向代理及加速缓存、即负载均衡功能（4 层以及 7 层），内置对 RS(real server)节点服务器健康检

查功能，这相当于专业的 Haproxy 软件或 LVS(4 层)的功能

具备 Squid 等专业缓存软件等的缓存功能（memcache/redis）

支持异步网络 I/O 事件模型 epoll (Linux 2.6+)

 

**nginx 总体性能为什么比 Apache 高**

Nginx 使用最新的 epoll(Linux2.6 内核)和 Kqueue(freebsd)异步网络 1O 模型

Apache 使用的是传统的 select 模型。

目前 Linux 下能够承受高并发访问的 Squid、Memcached 软件采用的都是 epoll 模型

 

**Apache select 和 nginx epoll 的技术对比**

| **指标**     | **select**                                                   | **epoll**                        |
| ------------ | ------------------------------------------------------------ | -------------------------------- |
| 性能         | 随着连接数的增加性能急剧下降，处理成千上万连接数性能很差     | 随着连接数的增加性能基本上没有下 |
| 连接数       | 连接数有限制，处理的最大连接数不 超过 1024，如果要处理的连接数超 过1024个，则需要修改FD_SETSIZE 宏，并重新编译 | 连接数无限制                     |
| 内在处理机制 | 线性轮询                                                     | 回调 callback                    |
| 开发复杂性低 | 低                                                           | 中                               |

 

**nginx 软件有哪些应用**

1）作为 Web 服务软件

2）反向代理或负载均衡服务

3）前端业务数据缓存服务（扩展 redis 缓存知识后）

 

 

**不同的业务选择的软件**

**静态业务**

若是高并发场景，尽量采用 Nginx 或 Lighttpd,二者首选 Nginx。

 

**动态业务**

理论上采用 Nginx 和 Apache 均可，建议选择 Nginx,为了避免相同业务的服务软件多样化，增加额外维护成本。动态业务可以由 Nginx 兼做前端代理，再根据页面元素的类型或目录，转发到后端相应的服务器处理进程。

 

**既有动态业务又有静态业务**

采用 Nginx

 

## 2、nginx日志管理与切割

**1、nginx日志管理**

**nginx日志描述**

通过访问日志，你可以得到用户地域来源、跳转来源、使用终端、某个URL访问量等相关信息；通过错误日志，你可以得到系统某个服务或server的性能瓶颈等。因此，将日志好好利用，你可以得到很多有价值的信息。

**Nginx日志格式**

打开nginx.conf配置文件：`vim /usr/local/nginx/conf/nginx.conf`

日志部分内容：

```
#access_log  logs/access.log  main;
```

日志生成的到Nginx根目录logs/access.log文件，默认使用“main”日志格式，也可以自定义格式。

**默认“main”日志格式：**

```json
log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '

                    '$status $body_bytes_sent "$http_referer" '

                    '"$http_user_agent" "$http_x_forwarded_for"';
```

参数明细表：

| $remote_addr          | 客户端的ip地址(代理服务器，显示代理服务ip)           |
| --------------------- | ---------------------------------------------------- |
| $remote_user          | 用于记录远程客户端的用户名称（一般为“-”）            |
| $time_local           | 用于记录访问时间和时区                               |
| $request              | 用于记录请求的url以及请求方法                        |
| $status               | 响应状态码，例如：200成功、404页面找不到等。         |
| $body_bytes_sent      | 给客户端发送的文件主体内容字节数                     |
| $http_user_agent      | 用户所使用的代理（一般为浏览器）                     |
| $http_x_forwarded_for | 可以记录客户端IP，通过代理服务器来记录客户端的ip地址 |
| $http_referer         | 可以记录用户是从哪个链接访问过来的                   |

> 注意：php，tomcat等后端服务获取的客户端ip等就是通过nginx传过来的



**2.nginx日志切割**

可以结合shell脚本实现，也可以使用日志切割工具（cronolog，）。

```shell
#!/bin/bash
s_log="/usr/local/nginx/logs/access.log"
d_log="/data/backup/nginx-$(date +%F).log"
d_log_dir="/data/backup"

#判断备份目录是否存在，不存在则创建
if [ ! -d "$d_log_dir" ];then
       mkdir -p "$d_log_dir"
fi

#判断原日志文件是否存在，存在则移动并改名
if [ -f "$s_log" ];then
        mv "$s_log" "$d_log"
fi

#以下两条命令任选其一：
#kill -USR1 `cat /usr/local/nginx/logs/nginx.pid`
/usr/local/nginx/sbin/nginx -s reopen
```

**创建crontab设置作业**

\#设置日志文件存放目录crontab -e

```shell
*/1 * * * *  /bin/bash /usr/local/nginx/nginx_log.sh
```

**nginx -s reopen**

执行完上述命令后，日志目录中自动生成了一个新的"access.log"文件，
再次访问nginx，会发现新生成的日志已经写入到了新生成的"access.log"文件中了。

**原理解析：**

发送信号，其实是执行：

```bash
kill -USR1 `cat /usrlocal/nginx/logs/nginx.pid`
```



## 3、nginx 管理常用的几个信号

**master进程接收的信号:**

| 信号名   | 含义                                   | 对应nginx命令行 |
| :------- | :------------------------------------- | :-------------- |
| TERM,INT | 终止进程                               | stop            |
| QUIT     | 完成请求链接,优雅的终止进程            | quit            |
| HUP      | 平滑重启，重新加载配置文件             | reload          |
| USR1     | 重新打开日志文件，在切割日志时用途较大 | reopen          |
| USR2     | 平滑升级,热部署使用                    | 无              |
| WINCH    | 平滑关闭进程,热部署使用                | 无              |

**worker接收的信号**

| 信号名   | 含义                        | 对应nginx命令行 |
| :------- | :-------------------------- | :-------------- |
| TERM,INT | 终止进程                    | stop            |
| QUIT     | 完成请求链接,优雅的终止进程 | quit            |
| WINCH    | 平滑关闭进程,热部署使用     | 无              |

**例子:**

为了更加直观,我们将nginx.conf worker进程改为1

```javascript
worker_processes  1;
```

**更改后,我们重新加载配置文件,可使用**

```javascript
nginx -s reload
```

> 或者可以使用 kill -HUP pid，pid需要你去查看nginx master进程pid获取. 此命令针对worker进程无效

**重新生成日志文件**

```javascript
 nginx -s reopen
 或者
 # kill -USR1 1144
```

**停掉子进程**

```shell
kill -TERM 1376
```



## 4、nginx 常用命令

```
nginx -s quit //优雅停止nginx，有连接时会等连接请求完成再杀死worker进程
nginx -s stop //快速关闭Nginx，可能不保存相关信息，并迅速终止web服务
nginx -s reload //优雅重启，并重新载入配置文件nginx.conf
nginx -s reopen //重新打开日志文件，一般用于切割日志
nginx -v //查看版本
nginx -t //检查nginx的配置文件
nginx -h //查看帮助信息
nginx -V //详细版本信息，包括编译参数
nginx -c filename //指定配置文件
```



## 5、nginx 跨域

直接请求nginx也是会报跨域错误的这里设置允许跨域;如果代理地址已经允许跨域则不需要这些, 否则报错(虽然这样nginx跨域就没意义了)

```shell
add_header Access-Control-Allow-Origin *;
add_header Access-Control-Allow-Headers X-Requested-With;
add_header Access-Control-Allow-Methods GET,POST,OPTIONS;
```



## 6、nginx 的 location 说明

location 表示位置的概念，类似于 if，即满足什么条件，就做什么

Nginx的location语法 

```
location [=|~|~*|^~] /uri/ { … }

=         严格匹配。如果请求匹配这个location，那么将停止搜索并立即处理此请求
~         区分大小写匹配(可用正则表达式)
~*        不区分大小写匹配(可用正则表达式)
!~        区分大小写不匹配
!~*       不区分大小写不匹配
^~        如果把这个前缀用于一个常规字符串,那么告诉nginx 如果路径匹配那么不测试正则表达式
```

 

示例1：

```
location  / { }
```

匹配任意请求

 

示例2：

```
location ~* .(gif|jpg|jpeg)$ ｛
	rewrite .(gif|jpg|jpeg)$ /logo.png;
｝
```

不区分大小写匹配任何以gif、jpg、jpeg结尾的请求，并将该请求重定向到 /logo.png请求

 

示例3：

```
location ~ ^.+\.txt$ {
	root /usr/local/nginx/html/;
}
```

区分大小写匹配以.txt结尾的请求，并设置此location的路径是/usr/local/nginx/html/。也就是以.txt结尾的请求将访问/usr/local/nginx/html/ 路径下的txt文件



## 7、nginx的alias与root的区别

root    实际访问文件路径会拼接URL中的路径
alias   实际访问文件路径不会拼接URL中的路径
示例如下：

```
location ^~ /sta/ {  
   alias /usr/local/nginx/html/static/;  
}
```

请求：http://test.com/sta/sta1.html
实际访问：/usr/local/nginx/html/static/sta1.html 文件

```
location ^~ /tea/ {  
   root /usr/local/nginx/html/;  
}
```

请求：http://test.com/tea/tea1.html
实际访问：/usr/local/nginx/html/tea/tea1.html 文件



## 8、nginx用户访问控制与认证模块

用户访问控制与认证模块ngx_http_access_module、ngx_http_auth_basic_module

**一、用户访问控制模块ngx_http_access_module**

如果在Nginx中想控制某个路径无法让指定用户访问（限制IP访问），需要使用到的模块是ngx_http_access_module。说模块名可能不熟悉，但是说到allow和deny就一定知道是干什么的了。这个模块是默认就会安装的，除非在编译时加上了--without-http_access_module。下面是ngx_http_access_module的配置语法示例：

```
location / {
	deny  192.168.1.120;
	allow 192.168.1.0/24;
	allow 10.1.1.0/16;
	deny  all;
}
```


Nginx和iptables的匹配规则一样，从上往下进行匹配，只要遇到符合条件的规则就不再继续往下匹配。如上例子中首先禁止192.168.1.120这个IP的访问，然后允许了另外2个网段的IP访问，最后不符合匹配条件的IP全部禁止访问。在实际工作中只要记住想禁止哪个IP访问就deny掉对应的IP，想允许则加上allow ip，想禁止或者允许所有的IP访问就使用allow all或者deny all。

**二、用户认证模块ngx_http_auth_basic_module**

Nginx进行用户名密码验证的话是通过ngx_http_auth_basic_module模块实现，该模块可作用范围http，server，location，limit_except，语法如下：

```
location / {
    auth_basic           "Please input your name";
    auth_basic_user_file /etc/nginx/htpasswd;
}
```



## 9、nginx的upstream模块和负载调度算法



**upstream模块相关说明**
1、upstream模块应放于nginx.conf配置的http{}标签内
2、upstream模块默认算法是wrr (权重轮询 weighted round-robin)

![1585367100786](assets/1585367100786.png)





**一、分配方式**
Nginx的upstream支持5种分配方式，下面将会详细介绍，其中前三种为Nginx原生支持的分配方式，后两种为第三方支持的分配方式。

1、rr轮询（默认调度算法，静态调度算法）
轮询是upstream的默认分配方式，即每个请求按照时间顺序轮流分配到不同的后端服务器，如果某个后端服务器down掉后，能自动剔除。

```shell
upstream backend {
    server 192.168.1.101:8888;
    server 192.168.1.102:8888;
    server 192.168.1.103:8888;
}
```

2、wrr（权重轮询，静态调度算法）
轮询的加强版，即可以指定轮询比率，weight和访问几率成正比，主要应用于后端服务器异质的场景下。

```shell
upstream backend {
    server 192.168.1.101 weight=1;
    server 192.168.1.102 weight=2;
    server 192.168.1.103 weight=3;
}
```

3、ip_hash（静态调度算法）
每个请求按照访问ip（即Nginx的前置服务器或者客户端IP）的hash结果分配，这样每个访客会固定访问一个后端服务器，可以解决session一致问题。

```shell
upstream backend {
    ip_hash;
    server 192.168.1.101:7777;
    server 192.168.1.102:8888;
	server 192.168.1.103:9999;
}
```

注意：
1、当负载调度算法为ip_hash时，后端服务器在负载均衡调度中的状态不能是weight和backup。
2、导致负载不均衡。



4、fair（动态调度算法）
fair顾名思义，公平地按照后端服务器的响应时间（rt）来分配请求，响应时间短即rt小的后端服务器优先分配请求。如果需要使用这种调度算法，必须下载Nginx的upstr_fair模块。

```shell
upstream backend {
    server 192.168.1.101;
	server 192.168.1.102;
    server 192.168.1.103;
    fair;
}
```

5、url_hash，目前用consistent_hash替代url_hash
与ip_hash类似，但是按照访问url的hash结果来分配请求，使得每个url定向到同一个后端服务器，主要应用于后端服务器为缓存时的场景下。

```shell
upstream backend {
    server 192.168.1.101;
    server 192.168.1.102;
    server 192.168.1.103;
    hash $request_uri;
    hash_method crc32;
}
```

 

其中，hash_method为使用的hash算法，需要注意的是：此时，server语句中不能加weight等参数。

提示：url_hash用途cache服务业务，memcached，squid，varnish。特点：每个rs都是不同的。



6、least_connleast_conn最小连接数算法

会根据后端节点的连接数来决定分配情况，哪个机器连接数少就分发。



## 10、常用的Nginx模块，用来做什么

```
rewrite模块，实现重写功能
access模块：来源控制
ssl模块：安全加密
ngx_http_gzip_module：网络传输压缩模块
ngx_http_proxy_module ：模块实现代理
ngx_http_upstream_module ：模块实现定义后端服务器列表
ngx_cache_purge ：实现缓存清除功能
```





# SHELL相关

## 1、Bash技巧：介绍 $0、$1、$2、$#、$@、$*、$? 的含义

在编写 Linux bash shell 脚本时，经常会用到 $0、$1、$2、$#、$@、$*、$? 等参数，下面具体说明这些参数的含义。

假设执行 **./test.sh a b c** 这样一个命令，则可以使用下面的参数来获取一些值：

- **$0** 对应 "**./test.sh**" 这个值。如果执行的是 ./work/test.sh， 则对应 ./work/test.sh 这个值，而不是只返回文件名本身的部分。
- **$1** 会获取到 a，即 $1 对应传给**脚本的第一个参数**。
- **$2** 会获取到 b，即 $2 对应传给**脚本的第二个参数**。
- **$3** 会获取到 c，即 $3 对应传给**脚本的第三个参数**。$4、$5 等参数的含义依此类推。
- **$#** 会获取到 3，对应传入**脚本的参数个数**，统计的参数不包括 $0。
- **$@** 会获取到 "a" "b" "c"，也就是**所有参数的列表**，不包括 $0。
- **$\*** 也会获取到 "a" "b" "c"， 其值**和 $@ 相同**。但 **$*** 和 **$@** 加上双引号有所不同。"$*" 把所有参数合并成一个字符串，而 "$@" 会得到一个字符串参数数组。
- **$?** 可以获取到执行 ./test.sh a b c 命令后的返回值。在执行一个前台命令后，可以立即用 $? 获取到该命令的返回值。该命令可以是系统自身的命令，可以是 shell 脚本，也可以是自定义的 bash 函数。0值为执行成功；非0值为执行失败。

| 变量 | 含义                                                         |
| ---- | ------------------------------------------------------------ |
| $0   | 当前脚本的文件名                                             |
| $n   | 传递给脚本或函数的参数。n 是一个数字，表示第几个参数。例如，第一个参数是$1，第二个参数是$2。 |
| $#   | 传递给脚本或函数的参数个数（不包含$0）。                     |
| $*   | 传递给脚本或函数的所有参数（"$*"会把所有参数当成一个字符串）。 |
| $@   | 传递给脚本或函数的所有参数。被双引号(" ")包含时，与 $* 稍有不同，下面将会讲到。（"$@"会把所有单数当成一个数组。） |
| $?   | 上个命令的退出状态，或函数的返回值。                         |
| $$   | 当前Shell进程ID。对于 Shell 脚本，就是这些脚本所在的进程ID。 |

通过脚本记忆特殊变量：

```shell
[root@ k8s-m01 ~]# cat test.sh
#!/bin/bash

echo "$0"
echo "$1"
echo "$2"
echo "$3"
echo "$#"
echo "$@"
echo "$*"
echo "$?"
[root@ k8s-m01 ~]# sh test.sh a b c
test.sh
a
b
c
3
a b c
a b c
0
```



下面举例说明 "$*" 和 "$@" 的差异。假设有一个 testparams.sh 脚本，内容如下：

```shell
[root@ k8s-m01 ~]# cat test.sh
#!/bin/bash

for i in "$*"
do
  echo '字符串:' $i
done

echo '----分割符----'

for i in "$@"
do
  echo '数组:' $i
done
[root@ k8s-m01 ~]# sh test.sh a b c
字符串: a b c
----分割符----
数组: a
数组: b
数组: c

```

可以看到，"$*" 只产生一个字符串，for 循环只遍历一次。
而 "$@" 产生了多个字符串，for 循环遍历多次，是一个字符串参数数组。

**注意**：如果传入的参数多于 9 个，则不能使用 $10 来引用第 10 个参数，而是要用 ${10} 来引用。即，需要用大括号{}把大于 9 的数字括起来。

例如，${10} 表示获取第 10 个参数的值，写为 $10 获取不到第 10 个参数的值。实际上，$10 相当于 ${1}0，也就是先获取 $1 的值，后面再跟上 0，如果 $1 的值是 "first"，则 $10 的值是 "first0"。



## **2、shell 中$() ，${}，$[] $(())，[ ] (( )) [[ ]]作用与区别**



**1.$()**

在 bash shell 中，$( ) 与 ` (反引号) 都是用来做命令替换用(commandsubstitution)的。 

例如 version=$(uname -r)和version= \uname -r都可以是version得到内核的版本号 

各自的优缺点： 

1. ` 基本上可用在全部的 unix shell 中使用，若写成 shell script ，其移植性比较高。但反单引号容易打错或看错。 

2. $()并不是所有shell都支持。

**2.${ } ：变量替换**

${}用于变量替换。一般情况下，$var 与${var} 并没有啥不一样。但是用 ${ } 会比较精确的界定变量名称的范围。比如

$A=B  $ echo $AB  

原本是打算先将 A的结果替换出来，然后再补一个B字母于其后，但在命令行上，真正的结果却是只会提换变量名称为AB的值出来…若使用$就没问题了：$echoA的结果替换出来，然后再补一个B字母于其后，但在命令行上，真正的结果却是只会提换变量名称为AB的值出来…若使用$就没问题了： $echo{A}B  BB 

${ }的功能远不止于此，详见下表。

![img](assets/clipboard-1585989849123.png)

**3.$ [] $ (()) :**

它们是一样的，都是进行数学运算的。支持+ - * / %：分别为 “加、减、乘、除、取模”。但是注意，bash只能作整数运算，对于浮点数是当作字符串处理的。

例：

```
$ a=5; b=7; c=2 $ echo $(( a+b*c )) 19 $ echo $(( (a+b)/c )) 6 $ echo $(( (a*b)%c)) 1 
```

在 $(( )) 中的变量名称，可于其前面加 $ 符号来替换，也可以不用，如：

$(( $a + $b * $c)) 也可得到 19 的结果 

此外，$(( )) 还可作不同进位(如二进制、八进位、十六进制)作运算呢，只是，输出结果皆为十进制而已：

echo $((16#2a)) 结果为 42 (16进位转十进制) 

**4.[ ]**

即为test命令的另一种形式。 

但要注意许多： 

1.你必须在左括号的右侧和右括号的左侧各加一个空格，否则会报错。 

2.test命令使用标准的数学比较符号来表示字符串的比较，而用文本符号来表示数值的比较。很多人会记反了。使用反了，shell可能得不到正确的结果。 

3.大于符号或小于符号必须要转义，否则会被理解成重定向。

**5.(( ))及[[ ]]**

它们分别是[ ]的针对数学比较表达式和字符串表达式的加强版。 

其中(( ))，不需要再将表达式里面的大小于符号转义，除了可以使用标准的数学运算符外，还增加了以下符号：！

![img](assets/clipboard-1585989849124.png)



## **3、shell脚本8种字符串截取方法总结**

Linux 的字符串截取很有用。有八种方法。

假设有变量 var=http://www.aaa.com/123.htm.

**1. # 号截取，删除左边字符，保留右边字符。**

echo ${var#*//}

其中 var 是变量名，# 号是运算符，*// 表示从左边开始删除第一个 // 号及左边的所有字符

即删除 http://

结果是 ：[www.aaa.com/123.htm](http://www.aaa.com/123.htm)

**2. ## 号截取，删除左边字符，保留右边字符。**

echo ${var##*/}

\##*/ 表示从左边开始删除最后（最右边）一个 / 号及左边的所有字符

即删除 http://www.aaa.com/

结果是 123.htm

**3. %号截取，删除右边字符，保留左边字符**

echo ${var%/*}

%/* 表示从右边开始，删除第一个 / 号及右边的字符

结果是：http://www.aaa.com

**4. %% 号截取，删除右边字符，保留左边字符**

echo ${var%%/*}

%%/* 表示从右边开始，删除最后（最左边）一个 / 号及右边的字符

结果是：http:

**5. 从左边第几个字符开始，及字符的个数**

echo ${var:0:5}

其中的 0 表示左边第一个字符开始，5 表示字符的总个数。

结果是：http:

**6. 从左边第几个字符开始，一直到结束。**

echo ${var:7}

其中的 7 表示左边第8个字符开始，一直到结束。

结果是 ：[www.aaa.com/123.htm](http://www.aaa.com/123.htm)

**7. 从右边第几个字符开始，及字符的个数**

echo ${var:0-7:3}

其中的 0-7 表示右边算起第七个字符开始，3 表示字符的个数。

结果是：123

**8. 从右边第几个字符开始，一直到结束。**

echo ${var:0-7}

表示从右边第七个字符开始，一直到结束。

结果是：123.htm

注：（左边的第一个字符是用 0 表示，右边的第一个字符用 0-1 表示）



## 4、shell数组和字典

**定义字典**

```shell
#!/bin/bash
echo "shell定义字典"
#必须先声明
declare -A dic
dic=([key1]="value1" [key2]="value2" [key3]="value3")
 
#打印指定key的value
echo ${dic["key1"]}
#打印所有key值
echo ${!dic[*]}
#打印所有value
echo ${dic[*]}
 
#遍历key值
for key in $(echo ${!dic[*]})
do
   echo "$key : ${dic[$key]}"
done
```

**定义数组**

```shell
#!/bin/bash
echo "shell定义数组"
#数组
list=("value1" "value2" "value3")
#打印指定下标
echo ${list[1]}
#打印所有下标
echo ${!list[*]}
#打印数组值
echo ${list[*]}
#数组增加一个元素
list=("${list[@]}" "value3")
```

​	





## 5、shell脚本--递归函数之Fork炸弹

Jaromil 在 2002 年设计了最为精简的一个Linux Fork炸弹，整个代码只有13个字符，在 shell 中运行后几秒后系统就会宕机：

```
:(){ :|:& };:
```

这样看起来不是很好理解，我们可以更改下格式：

```shell
:()
{
    :|:&
}
:
```

更好理解一点的话就是这样:

```shell
bomb()
{
    bomb|bomb&
};
bomb
```

因为shell中函数可以省略function关键字，所以上面的十三个字符是功能是定义一个函数与调用这个函数，函数的名称为:，主要的核心代码是:|:&，可以看出这是一个函数本身的递归调用，通过&实现在后台开启新进程运行，通过管道实现进程呈几何形式增长，最后再通过:来调用函数引爆炸弹。因此，几秒钟系统就会因为处理不过来太多的进程而死机，解决的唯一办法就是重启。

fork炸弹危害

Fork炸弹带来的后果就是耗尽服务器资源，使服务器不能正常的对外提供服务，也就是常说的DoS(Denial of Service)。与传统1v1、通过不断向服务器发送请求造成服务器崩溃不同，Fork炸弹有种坐山观虎斗，不费一兵一卒斩敌人于马下的感觉。更吓人的是这个函数是不需要root权限就可以运行的。


预防方式
当然，Fork炸弹没有那么可怕，用其它语言也可以分分钟写出来一个，例如，python版：

```python
import os
     while True: 
     os.fork()
```


Fork炸弹的本质无非就是靠创建进程来抢占系统资源，在Linux中，我们可以通过ulimit命令来限制用户的某些行为，运行ulimit -a可以查看我们能做哪些限制：

```shell
ubuntu@10-10-57-151:~$ ulimit -a
core file size          (blocks, -c) 0
data seg size           (kbytes, -d) unlimited
scheduling priority             (-e) 0
file size               (blocks, -f) unlimited
pending signals                 (-i) 7782
max locked memory       (kbytes, -l) 64
max memory size         (kbytes, -m) unlimited
open files                      (-n) 1024
pipe size            (512 bytes, -p) 8
POSIX message queues     (bytes, -q) 819200
real-time priority              (-r) 0
stack size              (kbytes, -s) 8192
cpu time               (seconds, -t) unlimited
max user processes              (-u) 7782
virtual memory          (kbytes, -v) unlimited
file locks                      (-x) unlimited
```

可以看到，-u参数可以限制用户创建进程数，因此，我们可以使用ulimit -u 20来允许用户最多创建20个进程。这样就可以预防bomb炸弹。但这样是不彻底的，关闭终端后这个命令就失效了。我们可以通过修改/etc/security/limits.conf文件来进行更深层次的预防，在文件里添加如下一行（ubuntu需更换为你的用户名）：

ubuntu - nproc 2

这个时候我们再次运行炸弹就不会报内存不足了，而是提示-bash: fork: retry: No child processes，说明Linux限制了炸弹创建进程。



## 6、shell脚本--多进程并发

**1.实现多进程：利用&元字符和wait关键字**

**单进程脚本：**

```shell
#!/bin/bash

start=`date +%s`
for i in `seq 4`
do
        echo $i;sleep 2
done

end=`date +%s`
echo "time: `expr $end - $start`"

[root@ localhost ~]# sh test.sh
1
2
3
4
time: 8
```

很明显是8s

这种不占处理器却有很耗时的进程，我们可以通过一种后台运行的方式
来达到节约时间的目的。看如下改进：

**多进程：**

```shell
#!/bin/bash

start=`date +%s`
for i in `seq 4`
do
	{
	echo $i;sleep 2
	}&
done
wait

end=`date +%s`
echo "time: `expr $end - $start`"

[root@ localhost ~]# sh test.sh
3
4
1
2
time: 2
```

用“{}”将主执行程序变为一个块，用&放入后台，四次执行全部放入后台后，我们需要用一个wait指令，等待所有后台进程执行结束，不然系统是不会等待的，直接继续执行后续指令，直到整个程序结束。
以上实验虽然达到了多线程并发的目的，但有一个缺陷，不能控制运行在后台的进程数。

用“{}”将主执行程序变为一个块，用&放入后台，四次执行全部放入后台后，我们需要用一个wait指令，等待所有后台进程执行结束，不然系统是不会等待的，直接继续执行后续指令，直到整个程序结束。
以上实验虽然达到了多线程并发的目的，但有一个缺陷，不能控制运行在后台的进程数。

**2.控制多进程: 管道 和文件操作符**

无名管道： 我们经常使用的 例如： cat text | grep "abc"
           那个“|”就是管道，只不过是无名的，可以直接作为两个进程的数据通道

有名管道： mkfilo  可以创建一个管道文件 ，例如： mkfifo fifo_file

管道有一个特点，如果管道中没有数据，那么取管道数据的操作就会停滞，直到管道内进入数据，然后读出后才会终止这一操作，同理，写入管道的操作如果没有读取操作，这一个动作也会停滞。

```shell
[root@ localhost ~]# mkfifo fifo_file
[root@ localhost ~]# echo "aaaaa" >fifo_file
```

当我们试图用echo想管道文件中写入数据时，由于没有任何进程在对它做读取操作，所以它会一直停留在那里等待读取操作，此时我们在另一终端上用cat指令做读取操作

```shell
[root@ localhost ~]# cat fifo_file
aaaaa
```



## 7、编写shell 脚本将/usr/local/test 目录下大于100K 的文件转移到/tmp目录下

```
find /usr/local/test -type f -size +100k -exec mv {} /tmp/
```

或

```shell
#!/bin/bash
filelist=$(ls  /usr/local/test -l | grep "^-" | awk '{print $9}')
filepath="/usr/local/test"
for file in $filelist
do
	filesize=$(du -s $filepath$file |awk '{print $1}') 
	if [ $filesize -gt 100]
		then
			mv $filepath$file /tmp/
	fi
done
```







## 8、linux中的sh、dash、bash的区别（了解）

**一、常见shell类型**

**1. Bourne shell (sh)**

UNIX 最初使用，且在每种 UNIX 上都可以使用。在 shell 编程方面相当优秀，但在处理与用户的交互方面做得不如其他几种shell。

**2. C shell (csh)**

csh, the C shell, is a command interpreter with a syntax similar to the C programming language.一个语法上接近于C语言的shell。

**3. Korn shell (ksh)**

完全向上兼容 Bourne shell 并包含了 C shell 的很多特性。

**4. Bourne Again shell (bash)**

因为Linux 操作系统缺省的 shell。即 bash 是 Bourne shell 的扩展，与 Bourne shell 完全向后兼容。在 Bourne shell 的基础上增加、增强了很多特性。可以提供如命令补全、命令编辑和命令历史表等功能。包含了很多 C shell 和 Korn shell 中的优点，有灵活和强大的编程接口，同时又有很友好的用户界面。

**5. Debian Almquist Shell(dash)**

原来bash是GNU/Linux 操作系统中的 /bin/sh 的符号连接，但由于bash过于复杂，有人把 bash 从 NetBSD 移植到 Linux 并更名为 dash，且/bin/sh符号连接到dash。Dash Shell 比 Bash Shell 小的多（ubuntu16.04上，bash大概1M，dash只有150K），符合POSIX标准。Ubuntu 6.10开始默认是Dash。

**二、规范和建议**

标记为 “#!/bin/sh” 的脚本不应使用任何 POSIX 没有规定的特性 (如 let 等命令, 但 “#!/bin/bash” 可以)。bash支持的写法比dash（ubuntu中的sh）多很多。想要支持 sh xx.sh 运行的，必须遵照 POSIX 规范去写。**想要脚本写法多样化，不需要考虑效率的，可以将文件头定义为 #!/bin/bash , 而且不要使用 sh xx.sh 这种运行方式**

**三、bash和dash区别**

语法上的主要的区别有:

**1. 定义函数**

bash: function在bash中为关键字

dash: dash中没有function这个关键字

**2. select var in list; do command; done**

bash:支持

dash:不支持, 替代方法:采用while+read+case来实现

**3. echo {0..10}**

bash:支持{n..m}展开

dash:不支持，替代方法, 采用seq外部命令

**4. here string**

bash:支持here string

dash:不支持, 替代方法:可采用here documents

**5. >&word重定向标准输出和标准错误**

bash: 当word为非数字时，>&word变成重定向标准错误和标准输出到文件word

dash: >&word, word不支持非数字, 替代方法: >word 2>&1; 常见用法 >/dev/null 2>&1

**6. 数组**

bash: 支持数组, bash4支持关联数组

dash: 不支持数组，替代方法, 采用变量名+序号来实现类似的效果

**7. 子字符串扩展**

bash: 支持parameter:offset:length,parameter:offset:length,{parameter:offset}

dash: 不支持， 替代方法:采用expr或cut外部命令代替

**8. 大小写转换**

bash: 支持parameterpattern,parameterpattern,{parameter^^pattern},parameter,pattern,parameter,pattern,{parameter,,pattern}

dash: 不支持，替代方法:采用tr/sed/awk等外部命令转换

**9. 进程替换<(command), >(command)**

bash: 支持进程替换

dash: 不支持, 替代方法, 通过临时文件中转

**10. [ string1 = string2 ] 和 [ string1 == string2 ]**

bash: 支持两者

dash: 只支持=

**11. [[ 加强版test**

bash: 支持[[ ]], 可实现正则匹配等强大功能

dash: 不支持[[ ]], 替代方法，采用外部命令

**12. for (( expr1 ; expr2 ; expr3 )) ; do list ; done**

bash: 支持C语言格式的for循环

dash: 不支持该格式的for, 替代方法，用while+((expression))实现13.let命令和((expression))bash:有内置命令let,也支持((expression))方式dash:不支持，替代方法，采用((expression))实现13.let命令和((expression))bash:有内置命令let,也支持((expression))方式dash:不支持，替代方法，采用((expression))或者外部命令做计算

**14. $((expression))**

bash: 支持id++,id–,++id,–id这样到表达式

dash: 不支持++,–, 替代方法:id+=1,id-=1, id=id+1,id=id-1

**15. 其它常用命令**

bash: 支持 echo -e, 支持 declare

dash: 不支持。





## 35、脚本判断192.168.1.0/24网络，当前在线的IP

> 注意：此脚本中涉及到了wait关键字和&符号，实现shell脚本多进程执行

```shell
for ip in seq 1 255
do
{
	ping -c 1 192.168.1.$ip > /dev/null 2>&1
	if [ $? -eq 0 ]; then
		echo 192.168.1.$ip UP
	else
		echo 192.168.1.$ip DOWN
	fi
}&
done
wait
```





## cat 多行写入文件防止变量替换

问题描述：对多个变量及多行输出到文件，存在变量自动替换，当使用cat<<EOF不想对内容进行变量替换、命令替换、参数展开等

问题解决：转义特殊字符如 $ ，``(反引号)等

一、对 $，``(反引号)等通过\ 进行转义

```shell
cat >> a.sh << EOF
echo \`hostname\`
echo \$HOME
EOF
```

 二、在分界符EOF前添加反斜杠\，或者用单引号、双引号括起来

```shell
cat >> a.sh << \EOF
echo `hostname`
echo $HOME
EOF

cat >> a.sh << "EOF"
echo `hostname`
echo $HOME
EOF

cat >> a.sh << 'EOF'
echo `hostname`
echo $HOME
EOF
```



## systemctl命令

systemctl在enable、disable、mask子命令里面增加了--now选项，可以激活同时启动服务，激活同时停止服务等。

```shell
立刻启动单元： systemctl start

立刻停止单元： systemctl stop

重启单元：systemctl restart

重新加载配置：systemctl reload

输出单元运行的状态：systemctl status

检测单元是否为自动启动：systemctl is-enabled

设置为开机自动激活单元：systemctl enable

设置为开机自动激活单元并现在立刻启动：systemctl enable --now

取消开机自动激活单元：systemctl disable

禁用一个单元：systemctl mask

取消禁用一个单元：systemctl unmask

显示单元的手册页（前提是由unit提供）：systemctl help

重新载入整个systemd的系统配置并扫描unit文件的变动：systemctl daemon-reload
```







# MYSQL相关

## 1、mysql主从同步原理

mysql 主从复制用途
实时灾备，用于故障切换
读写分离，提供查询服务
备份，避免影响业务

主从部署必要条件
主库开启 binlog 日志（设置 log-bin 参数）
主从 server-id 不同
从库服务器能连通主库

主从复制原理图：

![1585299402335](assets/1585299402335.png)

**该架构存在的问题：**

主库的宕机可能存在数据的丢失；当然从库也可能宕机，我们可以部署双从；

从库只有一个 SQL 线程，当用户的操作过多时，主库生成大量的 bin-log 二进制日志，从库可能忙不过来；

 

**数据库高可用介绍：**

我们使用的是 MHA 软件。

MHA 可以运行在每台 MySQL 服务器上，MHA 会定时探测集群中的 master 节点，当 master 出现故障时，它可以自动将最新数据的 slave 提升为新的 master，然后将所有其他的 slave 重新指向新的 master。整个故障转移过程对应用程序完全透明。

 

**MHA 的缺点：**

在 MHA 自动故障切换过程中，MHA 试图从宕机的主服务器上保存二进制日志，最大程度的保证数据的不丢失，但这并不总是可行的。例如，如果主服务器硬件故障或无法通过 ssh 访问，MHA 没法保存二进制日志，只进行故障转移而丢失了最新的数据。



## 2、mysql数据备份工具

mysqldump工具，mysqldump是mysql自带的备份工具，目录在bin目录下面：/usr/local/mysql/bin/mysqldump，支持基于innodb的热备份，但是由于是逻辑备份，所以速度不是很快，适合备份数据比较小的场景，Mysqldump完全备份+二进制日志可以实现基于时间点的恢复。

**基于LVM快照备份**

在物理备份中，有基于文件系统的物理备份（LVM的快照），也可以直接用tar之类的命令对整个数据库目录
进行打包备份，但是这些只能进行泠备份，不同的存储引擎备份的也不一样，myisam自动备份到表级别
而innodb不开启独立表空间的话只能备份整个数据库。

**tar包备份**

percona提供的xtrabackup工具，支持innodb的物理热备份，支持完全备份，增量备份，而且速度非常快，支持innodb存储引起的数据在不同，数据库之间迁移，支持复制模式下的从机备份恢复备份恢复，为了让xtrabackup支持更多的功能扩展，可以设立独立表空间，打开 innodb_file_per_table功能，启用之后可以支持单独的表备份



## 3、mysql的innodb如何定位锁问题，mysql如何减少主从复制延迟？

mysql的innodb如何定位锁问题:
在使用 show engine innodb status检查引擎状态时，发现了死锁问题
在5.5中，information_schema 库中增加了三个关于锁的表（MEMORY引擎）
innodb_trx         ## 当前运行的所有事务
innodb_locks     ## 当前出现的锁
innodb_lock_waits  ## 锁等待的对应关系

**mysql如何减少主从复制延迟:**

如果延迟比较大，就先确认以下几个因素：

1.从库硬件比主库差，导致复制延迟

2.主从复制单线程，如果主库写并发太大，来不及传送到从库就会导致延迟。

3.更高版本的mysql可以支持多线程复制

4.慢SQL语句过多

5.网络延迟

6.master负载，主库读写压力大，导致复制延迟，架构的前端要加buffer及缓存层

7.slave负载，一般的做法是，使用多台slave来分摊读请求，再从这些slave中取一台专用的服务器，只作为备份用，不进行其他任何操作.另外， 2个可以减少延迟的参数:–slave-net-timeout=seconds 单位为秒 默认设置为 3600秒

参数含义：当slave从主数据库读取log数据失败后，等待多久重新建立连接并获取数据

–master-connect-retry=seconds 单位为秒 默认设置为 60秒

参数含义：当重新建立主从连接时，如果连接建立失败，间隔多久后重试

通常配置以上2个参数可以减少网络问题导致的主从数据同步延迟

**MySQL数据库主从同步延迟解决方案**

最简单的减少slave同步延时的方案就是在架构上做优化，尽量让主库的DDL快速执行，还有就是主库是写（读写分离），对数据安全性较高，比如sync_binlog=1，innodb_flush_log_at_trx_commit= 1 之类的设置，而slave则不需要这么高的数据安全，完全可以讲sync_binlog设置为0或者关闭binlog，innodb_flushlog也可以设置为0来提高sql的执行效率。另外就是使用比主库更好的硬件设备作为slave

## 4、如何重置mysql root密码？

一、 在已知MYSQL数据库的ROOT用户密码的情况下，修改密码的方法：

1、 在SHELL环境下，使用mysqladmin命令设置：

```
mysqladmin –u root –p password “新密码”   回车后要求输入旧密码
```

2、 在mysql>环境中,使用update命令，直接更新mysql库user表的数据：

```
Update  mysql.user  set  password=password(‘新密码’)  where  user=’root’;
flush   privileges;
```


​      注意：mysql语句要以分号”；”结束

3、 在mysql>环境中，使用grant命令，修改root用户的授权权限。

```
grant  all  on  *.*  to   root@’localhost’  identified  by  ‘新密码’；
```

二、 如查忘记了mysql数据库的ROOT用户的密码，又如何做呢？方法如下：

1、 关闭当前运行的mysqld服务程序：service  mysqld  stop（要先将mysqld添加为系统服务）
2、 使用mysqld_safe脚本以安全模式（不加载授权表）启动mysqld 服务

```
 /usr/local/mysql/bin/mysqld_safe  –skip-grant-table  &
```

3、 使用空密码的root用户登录数据库，重新设置ROOT用户的密码

```
＃mysql  -u   root
Mysql> Update  mysql.user  set  password=password(‘新密码’)  where  user=’root’;
Mysql> flush   privileges;
```



## Mysql主从同步延迟问题及解决方案

问题一：主库的从库太多，导致复制延迟

从库数据以3-5个为宜，要复制的从节点数量过多，会导致复制延迟



问题二：从库硬件比主库差，导致复制延迟

查看Master和Slave的系统配置，可能会因为机器配置不当，包括磁盘I/O、CPU、内存等各方面因素造成复制的延迟。一般发生在高并发大数据量写入场景中



问题三：慢SQL语句过多

假如一条SQL语句执行时间是20秒，那么从执行完毕到从库上能查到数据至少需要20秒，这样就延迟20秒了。

一般要把SQL语句的优化作为常规工作不断地进行监控和优化，如果单个SQL的写入时间长，可以修改后分多次写入。通过查看慢查询日志或show full processlist命令，找出执行时间长的查询语句或大的事务



问题四：主从复制的设计问题

例如主从复制单线程，如果主库写并发太大，来不及传送到从库，就会导致延迟。更高版本的Mysql可以支持多线程复制，门户网站则会开发自己的多线程同步功能。



问题五：主从库之间的网络延迟

主从库的网卡、网线、交换机等网络设备都可能成为复制的瓶颈，导致复制延迟。另外，跨公网的主从复制很容易导致主从复制延迟



问题六：主库读写压力大，导致复制延迟

架构的前端要加buffer及缓存层



门户网站的解决方案：

优酷的解决方案：数据库分片技术，而抛弃了由于数据量的越来越多导致复制延迟的问题。按照user_id进行分片，这样必须有一个全局的表来管理用户与shard的关系,根据user_id可以得到share_id，然后根据share_id去指定的分片查询指定的数据



淘宝的解决方案：修改源码，对应的机制是Transfer机制，此处通过对Binlog日志重做采用多线程实现，从而提高slave的QPPS







